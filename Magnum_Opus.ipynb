{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGNUM OPUS\n",
    "IMPORTING THE DOCS FROM PROJECT GUTENBERG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n\\r\\nThis eBook is for the '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "type(raw)\n",
    "len(raw)\n",
    "raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n\\r\\nThis eBook is for the '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/63072/63072-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw1 = response.read().decode('utf8')\n",
    "type(raw1)\n",
    "len(raw1)\n",
    "raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary=True)\n",
    "vect.fit([raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5920364]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([raw1]),vect.transform([raw]))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKING THE SAME DOCS AFTER APPLYING PORTER STEMMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ther and mother spent their evenings\\r\\nin read aloud to their children, gener from book of a serious\\r\\ncharacter.\\r\\n\\r\\nthough alway sickli and delic dostoevski came out third in the\\r\\nfin examin of the petersburg school of engineering. there he had\\r\\nalreadi begun hi first work, “poor folk.”\\r\\n\\r\\nthi stori wa publish by the poet nekrassov in hi review and\\r\\nwa receiv with acclamations. the shy, unknown you'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "raw_stem = [porter.stem(token) for token in raw.split(\" \")]\n",
    "raw_stem = \" \".join(raw_stem)\n",
    "raw_stem[1000:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n\\r\\ndodg citi reap it harvest from the great northward trek of the\\r\\nlonghorns.\\r\\n\\r\\nth big trek is a thing of the past; the trail itself lost,\\r\\nforgotten. dodg citi ha long sinc settl down to most proper\\r\\nrespectability. and those hard-fisted, quick-shoot men who\\r\\nsquand their wealth and lives, there, along the way from santa\\r\\nfe, have depart to that limbo from which none return.\\r\\n\\r\\nbut a practic eye'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1_stem = [porter.stem(token) for token in raw1.split(\" \")]\n",
    "raw1_stem = \" \".join(raw1_stem)\n",
    "raw1_stem[5000:5400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1 = CountVectorizer(binary=True)\n",
    "vect1.fit([raw_stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58641038]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity1 = cosine_similarity(vect1.transform([raw1_stem]),vect1.transform([raw_stem]))\n",
    "print(similarity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKING THE SAME DOCS AFTER APPLYING LANCASTER STEMMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'their evenings\\r\\nin read aloud to their children, gen from book of a serious\\r\\ncharacter.\\r\\n\\r\\nthough alway sick and del dostoevsky cam out third in the\\r\\nfinal examin of the petersburg school of engineering. ther he had\\r\\nalready begun his first work, “poor folk.”\\r\\n\\r\\nthis story was publ by the poet nekrassov in his review and\\r\\nwas receiv with acclamations. the shy, unknown you found himself\\r\\ninstantly '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "Lstem = LancasterStemmer()\n",
    "raw_lstem = [Lstem.stem(token) for token in raw.split(\" \")]\n",
    "raw_lstem = \" \".join(raw_lstem)\n",
    "raw_lstem[1000:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlonghorns.\\r\\n\\r\\nth big trek is a thing of the past; the trail itself lost,\\r\\nforgotten. dodg city has long sint settl down to most proper\\r\\nrespectability. and thos hard-fisted, quick-shooting men who\\r\\nsquandered their weal and lives, there, along the way from santa\\r\\nfe, hav depart to that limbo from which non return.\\r\\n\\r\\nbut a pract ey would hav said that the man who rod into\\r\\nstanding rock thi day w'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1_lstem = [Lstem.stem(token) for token in raw1.split(\" \")]\n",
    "raw1_lstem = \" \".join(raw1_lstem)\n",
    "raw1_lstem[5000:5400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2 = CountVectorizer(binary=True)\n",
    "vect2.fit([raw_lstem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59062644]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity2 = cosine_similarity(vect2.transform([raw1_lstem]),vect2.transform([raw_lstem]))\n",
    "print(similarity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
